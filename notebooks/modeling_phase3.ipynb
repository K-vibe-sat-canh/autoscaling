{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff174af",
   "metadata": {},
   "source": [
    "# üöÄ Phase 3: Traffic Forecasting Models\n",
    "\n",
    "## NASA HTTP Log Data - Autoscaling Competition\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- Train/Test Split: Train (Jul 1 - Aug 22), Test (Aug 23 - Aug 31)\n",
    "- D·ª± b√°o: `request_count` v√† `total_bytes`\n",
    "- Models: **Prophet** + **XGBoost**\n",
    "- Metrics: RMSE, MAE, MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f7aad",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7370f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Time Series\n",
    "from prophet import Prophet\n",
    "\n",
    "# Config\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70360308",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cee842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 5-minute aggregated data\n",
    "DATA_PATH = \"../processed_data/nasa_traffic_5m.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['timestamp'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)  # Remove timezone\n",
    "\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üìÖ Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"\\nüîç Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1912d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data gap (Hurricane: Aug 1 14:52 - Aug 3 04:36)\n",
    "df = df.set_index('timestamp').sort_index()\n",
    "\n",
    "# Visualize data availability\n",
    "fig = px.scatter(df.reset_index(), x='timestamp', y='request_count', \n",
    "                 title='üìà Request Count Over Time (Note the gap in early August)')\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf625d34",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "**Theo y√™u c·∫ßu cu·ªôc thi:**\n",
    "- **Train Set:** July 1 ‚Üí August 22, 1995\n",
    "- **Test Set:** August 23 ‚Üí August 31, 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split date\n",
    "SPLIT_DATE = '1995-08-23'\n",
    "\n",
    "# Split data\n",
    "train_df = df[df.index < SPLIT_DATE].copy()\n",
    "test_df = df[df.index >= SPLIT_DATE].copy()\n",
    "\n",
    "print(f\"üìä Train set: {len(train_df)} samples\")\n",
    "print(f\"   From: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"\\nüìä Test set: {len(test_df)} samples\") \n",
    "print(f\"   From: {test_df.index.min()} to {test_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05160f3",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "T·∫°o c√°c features cho XGBoost:\n",
    "- **Time features:** hour, day_of_week, day_of_month, is_weekend\n",
    "- **Lag features:** lag_1, lag_2, lag_3, lag_12 (1h), lag_288 (1 day @ 5min interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create time-based and lag features for ML model\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Time features\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['day_of_month'] = df.index.day\n",
    "    df['is_weekend'] = (df.index.dayofweek >= 5).astype(int)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    # Lag features for request_count\n",
    "    for lag in [1, 2, 3, 6, 12, 288]:  # 5min, 10min, 15min, 30min, 1h, 1day\n",
    "        df[f'request_lag_{lag}'] = df['request_count'].shift(lag)\n",
    "        df[f'bytes_lag_{lag}'] = df['total_bytes'].shift(lag)\n",
    "    \n",
    "    # Rolling statistics (1 hour = 12 intervals of 5min)\n",
    "    df['request_rolling_mean_1h'] = df['request_count'].rolling(12).mean()\n",
    "    df['request_rolling_std_1h'] = df['request_count'].rolling(12).std()\n",
    "    df['bytes_rolling_mean_1h'] = df['total_bytes'].rolling(12).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to full dataset first, then split\n",
    "df_features = create_features(df)\n",
    "\n",
    "# Re-split after feature engineering\n",
    "train_features = df_features[df_features.index < SPLIT_DATE].copy()\n",
    "test_features = df_features[df_features.index >= SPLIT_DATE].copy()\n",
    "\n",
    "# Drop NaN rows (from lag features)\n",
    "train_features = train_features.dropna()\n",
    "test_features = test_features.dropna()\n",
    "\n",
    "print(f\"‚úÖ Features created!\")\n",
    "print(f\"   Train: {len(train_features)} samples\")\n",
    "print(f\"   Test: {len(test_features)} samples\")\n",
    "print(f\"\\nüìã Feature columns: {[c for c in train_features.columns if c not in df.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c69b7",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Calculate RMSE, MAE, MAPE\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # MAPE - avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    \n",
    "    print(f\"\\nüìä {model_name} Performance:\")\n",
    "    print(f\"   RMSE: {rmse:,.2f}\")\n",
    "    print(f\"   MAE:  {mae:,.2f}\")\n",
    "    print(f\"   MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'mape': mape}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1eda01",
   "metadata": {},
   "source": [
    "---\n",
    "# üîÆ MODEL 1: Facebook Prophet\n",
    "\n",
    "Prophet l√† model time-series c·ªßa Facebook, t·ªët cho:\n",
    "- D·ªØ li·ªáu c√≥ seasonality (daily, weekly)\n",
    "- X·ª≠ l√Ω missing data t·ª± ƒë·ªông\n",
    "- D·ªÖ tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0470f16",
   "metadata": {},
   "source": [
    "### 6.1 Prophet - Request Count Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08679700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet (requires 'ds' and 'y' columns)\n",
    "prophet_train_requests = train_df.reset_index()[['timestamp', 'request_count']].rename(\n",
    "    columns={'timestamp': 'ds', 'request_count': 'y'}\n",
    ")\n",
    "\n",
    "# Initialize and train Prophet model\n",
    "print(\"üîÑ Training Prophet model for Request Count...\")\n",
    "prophet_requests = Prophet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=False,  # Only 2 months of data\n",
    "    changepoint_prior_scale=0.05,  # Regularization\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "prophet_requests.fit(prophet_train_requests)\n",
    "print(\"‚úÖ Prophet model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "prophet_test_requests = test_df.reset_index()[['timestamp']].rename(columns={'timestamp': 'ds'})\n",
    "prophet_pred_requests = prophet_requests.predict(prophet_test_requests)\n",
    "\n",
    "# Get predictions\n",
    "y_true_requests = test_df['request_count'].values\n",
    "y_pred_requests_prophet = prophet_pred_requests['yhat'].values\n",
    "\n",
    "# Evaluate\n",
    "prophet_request_metrics = calculate_metrics(\n",
    "    y_true_requests, \n",
    "    y_pred_requests_prophet, \n",
    "    \"Prophet - Request Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b77f13",
   "metadata": {},
   "source": [
    "### 6.2 Prophet - Total Bytes Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Prophet - Total Bytes\n",
    "prophet_train_bytes = train_df.reset_index()[['timestamp', 'total_bytes']].rename(\n",
    "    columns={'timestamp': 'ds', 'total_bytes': 'y'}\n",
    ")\n",
    "\n",
    "# Train Prophet model for bytes\n",
    "print(\"üîÑ Training Prophet model for Total Bytes...\")\n",
    "prophet_bytes = Prophet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=False,\n",
    "    changepoint_prior_scale=0.05,\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "prophet_bytes.fit(prophet_train_bytes)\n",
    "\n",
    "# Predict\n",
    "prophet_pred_bytes = prophet_bytes.predict(prophet_test_requests)\n",
    "\n",
    "# Evaluate\n",
    "y_true_bytes = test_df['total_bytes'].values\n",
    "y_pred_bytes_prophet = prophet_pred_bytes['yhat'].values\n",
    "\n",
    "prophet_bytes_metrics = calculate_metrics(\n",
    "    y_true_bytes, \n",
    "    y_pred_bytes_prophet, \n",
    "    \"Prophet - Total Bytes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ec1c1",
   "metadata": {},
   "source": [
    "---\n",
    "# üå≤ MODEL 2: XGBoost\n",
    "\n",
    "XGBoost l√† gradient boosting model m·∫°nh cho tabular data:\n",
    "- S·ª≠ d·ª•ng lag features v√† time features\n",
    "- Nhanh v√† hi·ªáu qu·∫£\n",
    "- D·ªÖ interpret feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a9046",
   "metadata": {},
   "source": [
    "### 7.1 XGBoost - Request Count Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (exclude target and original columns)\n",
    "feature_cols = [col for col in train_features.columns if col not in [\n",
    "    'request_count', 'total_bytes', 'status_2xx', 'status_3xx', \n",
    "    'status_4xx', 'status_5xx', 'is_outage'\n",
    "]]\n",
    "\n",
    "print(f\"üìã Features used: {feature_cols}\")\n",
    "\n",
    "# Prepare train/test data\n",
    "X_train = train_features[feature_cols]\n",
    "y_train_requests = train_features['request_count']\n",
    "y_train_bytes = train_features['total_bytes']\n",
    "\n",
    "X_test = test_features[feature_cols]\n",
    "y_test_requests = test_features['request_count']\n",
    "y_test_bytes = test_features['total_bytes']\n",
    "\n",
    "print(f\"\\n‚úÖ X_train shape: {X_train.shape}\")\n",
    "print(f\"‚úÖ X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a978902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost for Request Count\n",
    "print(\"üîÑ Training XGBoost model for Request Count...\")\n",
    "\n",
    "xgb_requests = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_requests.fit(X_train, y_train_requests)\n",
    "print(\"‚úÖ XGBoost model trained!\")\n",
    "\n",
    "# Predict\n",
    "y_pred_requests_xgb = xgb_requests.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "xgb_request_metrics = calculate_metrics(\n",
    "    y_test_requests.values, \n",
    "    y_pred_requests_xgb, \n",
    "    \"XGBoost - Request Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d1bf3",
   "metadata": {},
   "source": [
    "### 7.2 XGBoost - Total Bytes Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost for Total Bytes\n",
    "print(\"üîÑ Training XGBoost model for Total Bytes...\")\n",
    "\n",
    "xgb_bytes = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_bytes.fit(X_train, y_train_bytes)\n",
    "\n",
    "# Predict\n",
    "y_pred_bytes_xgb = xgb_bytes.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "xgb_bytes_metrics = calculate_metrics(\n",
    "    y_test_bytes.values, \n",
    "    y_pred_bytes_xgb, \n",
    "    \"XGBoost - Total Bytes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd245863",
   "metadata": {},
   "source": [
    "### 7.3 XGBoost Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Request Count model\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_requests.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig = px.bar(importance_df.head(15), x='importance', y='feature', \n",
    "             orientation='h', title='üîç Top 15 Feature Importance (XGBoost - Request Count)')\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69baa64b",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Model Comparison & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Model': ['Prophet', 'Prophet', 'XGBoost', 'XGBoost'],\n",
    "    'Target': ['Request Count', 'Total Bytes', 'Request Count', 'Total Bytes'],\n",
    "    'RMSE': [\n",
    "        prophet_request_metrics['rmse'],\n",
    "        prophet_bytes_metrics['rmse'],\n",
    "        xgb_request_metrics['rmse'],\n",
    "        xgb_bytes_metrics['rmse']\n",
    "    ],\n",
    "    'MAE': [\n",
    "        prophet_request_metrics['mae'],\n",
    "        prophet_bytes_metrics['mae'],\n",
    "        xgb_request_metrics['mae'],\n",
    "        xgb_bytes_metrics['mae']\n",
    "    ],\n",
    "    'MAPE (%)': [\n",
    "        prophet_request_metrics['mape'],\n",
    "        prophet_bytes_metrics['mape'],\n",
    "        xgb_request_metrics['mape'],\n",
    "        xgb_bytes_metrics['mape']\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"üìä MODEL COMPARISON - Test Set (Aug 23 - Aug 31, 1995)\")\n",
    "print(\"=\"*70)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d485808",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Visualization: Actual vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Request Count - Actual vs Predicted\n",
    "fig = make_subplots(rows=2, cols=1, \n",
    "                    subplot_titles=('Prophet - Request Count', 'XGBoost - Request Count'),\n",
    "                    vertical_spacing=0.12)\n",
    "\n",
    "# Prophet predictions\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_df.index, y=y_true_requests, name='Actual', \n",
    "               line=dict(color='blue', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_df.index, y=y_pred_requests_prophet, name='Prophet Predicted',\n",
    "               line=dict(color='red', width=1, dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# XGBoost predictions  \n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_features.index, y=y_test_requests, name='Actual',\n",
    "               line=dict(color='blue', width=1), showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_features.index, y=y_pred_requests_xgb, name='XGBoost Predicted',\n",
    "               line=dict(color='green', width=1, dash='dash')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, title_text=\"üìà Request Count: Actual vs Predicted (Test Set)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105333bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Total Bytes - Actual vs Predicted\n",
    "fig = make_subplots(rows=2, cols=1, \n",
    "                    subplot_titles=('Prophet - Total Bytes', 'XGBoost - Total Bytes'),\n",
    "                    vertical_spacing=0.12)\n",
    "\n",
    "# Prophet predictions\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_df.index, y=y_true_bytes, name='Actual', \n",
    "               line=dict(color='blue', width=1)),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_df.index, y=y_pred_bytes_prophet, name='Prophet Predicted',\n",
    "               line=dict(color='red', width=1, dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# XGBoost predictions  \n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_features.index, y=y_test_bytes, name='Actual',\n",
    "               line=dict(color='blue', width=1), showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=test_features.index, y=y_pred_bytes_xgb, name='XGBoost Predicted',\n",
    "               line=dict(color='green', width=1, dash='dash')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, title_text=\"üìä Total Bytes: Actual vs Predicted (Test Set)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69c0ba",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7dda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Save models\n",
    "MODEL_DIR = \"../saved_models\"\n",
    "\n",
    "# Save Prophet models\n",
    "with open(f\"{MODEL_DIR}/prophet_requests.pkl\", \"wb\") as f:\n",
    "    pickle.dump(prophet_requests, f)\n",
    "    \n",
    "with open(f\"{MODEL_DIR}/prophet_bytes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(prophet_bytes, f)\n",
    "\n",
    "# Save XGBoost models  \n",
    "xgb_requests.save_model(f\"{MODEL_DIR}/xgb_requests.json\")\n",
    "xgb_bytes.save_model(f\"{MODEL_DIR}/xgb_bytes.json\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_summary = {\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "    'train_period': 'July 1 - August 22, 1995',\n",
    "    'test_period': 'August 23 - August 31, 1995',\n",
    "    'models': {\n",
    "        'prophet_requests': prophet_request_metrics,\n",
    "        'prophet_bytes': prophet_bytes_metrics,\n",
    "        'xgb_requests': xgb_request_metrics,\n",
    "        'xgb_bytes': xgb_bytes_metrics\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{MODEL_DIR}/metrics_summary.json\", \"w\") as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ All models saved to ../saved_models/\")\n",
    "print(\"   - prophet_requests.pkl\")\n",
    "print(\"   - prophet_bytes.pkl\")\n",
    "print(\"   - xgb_requests.json\")\n",
    "print(\"   - xgb_bytes.json\")\n",
    "print(\"   - metrics_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22d953",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Phase 4: Autoscaling Simulation\n",
    "\n",
    "S·ª≠ d·ª•ng d·ª± b√°o ƒë·ªÉ simulate autoscaling v·ªõi cooldown/hysteresis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63767ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_autoscaling(predicted_loads, \n",
    "                         capacity_per_server=500,  # requests per 5min per server\n",
    "                         scale_up_threshold=0.8,\n",
    "                         scale_down_threshold=0.3,\n",
    "                         cooldown_periods=6,  # 6 x 5min = 30min cooldown\n",
    "                         min_servers=1,\n",
    "                         max_servers=20):\n",
    "    \"\"\"\n",
    "    Simulate autoscaling based on predicted traffic.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predicted_loads: array of predicted request counts\n",
    "    capacity_per_server: max requests one server can handle per interval\n",
    "    scale_up_threshold: utilization % to trigger scale up (default 80%)\n",
    "    scale_down_threshold: utilization % to trigger scale down (default 30%)\n",
    "    cooldown_periods: number of intervals to wait between scaling actions\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with scaling decisions\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    current_servers = 2  # Start with 2 servers\n",
    "    last_scale_time = -cooldown_periods  # Allow immediate first scaling\n",
    "    \n",
    "    for i, load in enumerate(predicted_loads):\n",
    "        capacity = current_servers * capacity_per_server\n",
    "        utilization = load / capacity if capacity > 0 else 1.0\n",
    "        \n",
    "        action = \"maintain\"\n",
    "        reason = \"\"\n",
    "        \n",
    "        # Check if cooldown has passed\n",
    "        if i - last_scale_time >= cooldown_periods:\n",
    "            if utilization > scale_up_threshold:\n",
    "                # Scale up\n",
    "                needed_servers = int(np.ceil(load / (capacity_per_server * 0.7)))  # Target 70% util\n",
    "                new_servers = min(max_servers, max(current_servers + 1, needed_servers))\n",
    "                if new_servers > current_servers:\n",
    "                    action = \"scale_up\"\n",
    "                    reason = f\"Utilization {utilization:.1%} > {scale_up_threshold:.0%}\"\n",
    "                    current_servers = new_servers\n",
    "                    last_scale_time = i\n",
    "                    \n",
    "            elif utilization < scale_down_threshold:\n",
    "                # Scale down\n",
    "                new_servers = max(min_servers, current_servers - 1)\n",
    "                if new_servers < current_servers:\n",
    "                    action = \"scale_down\"\n",
    "                    reason = f\"Utilization {utilization:.1%} < {scale_down_threshold:.0%}\"\n",
    "                    current_servers = new_servers\n",
    "                    last_scale_time = i\n",
    "        else:\n",
    "            reason = f\"Cooldown ({cooldown_periods - (i - last_scale_time)} periods left)\"\n",
    "        \n",
    "        results.append({\n",
    "            'period': i,\n",
    "            'predicted_load': load,\n",
    "            'servers': current_servers,\n",
    "            'capacity': current_servers * capacity_per_server,\n",
    "            'utilization': utilization,\n",
    "            'action': action,\n",
    "            'reason': reason\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run simulation with XGBoost predictions\n",
    "scaling_results = simulate_autoscaling(y_pred_requests_xgb)\n",
    "print(\"üñ•Ô∏è Autoscaling Simulation Results:\")\n",
    "print(f\"   Total periods: {len(scaling_results)}\")\n",
    "print(f\"   Scale up events: {(scaling_results['action'] == 'scale_up').sum()}\")\n",
    "print(f\"   Scale down events: {(scaling_results['action'] == 'scale_down').sum()}\")\n",
    "print(f\"   Server range: {scaling_results['servers'].min()} - {scaling_results['servers'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89964c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize autoscaling simulation\n",
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    subplot_titles=('Predicted Load & Server Capacity', 'Number of Active Servers'),\n",
    "                    vertical_spacing=0.15)\n",
    "\n",
    "# Load vs Capacity\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=scaling_results['predicted_load'], name='Predicted Load',\n",
    "               line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=scaling_results['capacity'], name='Server Capacity',\n",
    "               line=dict(color='green', dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Number of servers\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=scaling_results['servers'], name='Active Servers',\n",
    "               line=dict(color='orange'), fill='tozeroy'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Mark scale events\n",
    "scale_up_idx = scaling_results[scaling_results['action'] == 'scale_up'].index\n",
    "scale_down_idx = scaling_results[scaling_results['action'] == 'scale_down'].index\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=scale_up_idx, y=scaling_results.loc[scale_up_idx, 'servers'],\n",
    "               mode='markers', name='Scale Up', marker=dict(color='red', size=10, symbol='triangle-up')),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=scale_down_idx, y=scaling_results.loc[scale_down_idx, 'servers'],\n",
    "               mode='markers', name='Scale Down', marker=dict(color='blue', size=10, symbol='triangle-down')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"üñ•Ô∏è Autoscaling Simulation (with Cooldown)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce792d5e",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "### Models Trained:\n",
    "1. **Prophet** - Time series model v·ªõi daily/weekly seasonality\n",
    "2. **XGBoost** - Gradient boosting v·ªõi lag features\n",
    "\n",
    "### Key Results:\n",
    "- Train: July 1 - August 22, 1995\n",
    "- Test: August 23 - August 31, 1995\n",
    "- Evaluated on: Request Count & Total Bytes\n",
    "- Metrics: RMSE, MAE, MAPE\n",
    "\n",
    "### Next Steps:\n",
    "1. Fine-tune hyperparameters\n",
    "2. Try ensemble methods\n",
    "3. Integrate with live dashboard\n",
    "4. Deploy autoscaling logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
